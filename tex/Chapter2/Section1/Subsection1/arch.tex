\documentclass{standalone}
\begin{document}
\subsection{Architecture}

A CNN architecture is made by a stack of distinct layers.
The most common ones are:

\paragraph{Convolutional Layer} is the core of the CNN architecture.
The layer consist in a set of filters (kernels).
During the training, each filter is convolved across the width and height of the input, producing an \textit{activation map} of that filter\cite{wiki:cnn, CNN}. 

\paragraph{ReLu Layer}
consists in the application of the Rectified Linear Unit (ReLu) activation function. 
It consists in removing negative values from an activation map by setting them to zero: $f(x)= \max (0, x)$.

\paragraph{Pooling Layer}
consists in a non-linear down-sampling.
The most common one is the so called \textit{max pooling}\cite{wiki:cnn}.
It partitions the input image into a set of rectangles and, for each such sub-region, outputs the maximum.

\paragraph{Fully connected layer}
is similar to the way that neurons are arranged in a traditional neural network.
Each neuron consists in a flatten matrix connected in one layer to every neuron of another layer.


\paragraph{Loss Layer}
consists in the application of a loss function which specifies how training penalizes the deviation between the predicted output of the network, and the true data labels (during supervised learning).
Depending on the task, different loss functions can be used.
For example, the binary cross-entropy loss can be used for binary (0, 1) applications while for regression application the mean squared error.

\paragraph{\textcolor{blue}{Notes:} Metrics:} 
A metric is a function that is used to judge the performance of your model.
Metric functions are similar to loss functions, except that the results from evaluating a metric are not used when training the model.
As for the loss function, different metrics can be used for the evaluation.
For example, Dice coefficient and Intersection Over Union (IoU) can be used for segmentation purposes.

\end{document}