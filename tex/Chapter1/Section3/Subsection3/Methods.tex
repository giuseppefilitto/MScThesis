\documentclass{standalone}
\begin{document}
\subsection{Segmentation Methods Review}
Many segmentation methods have been developed over the years. 
The choice of the best segmentation method depends by the particular type of image and characteristics of the problem being considered\cite{imagesegmentation}.
There are various ways to classify these methods.
For example, depending if they require or not a training set of data, they can be classified into \textit{supervised} or \textit{unsupervised} methods.
Moreover, they can be classified depending on the information type they use, like \textit{Pixel classification} methods, which use only information about pixel intensity, or \textit{Boundary following} methods that use edge information etc...\cite{biondi}.
\\
At this point, I will provide a brief summary of one of the most common manual/semi-manual approach such as Thresholding. Then, I will focus on Convolutional Neural Networks and in particular on the U-Net architecture.


\subsubsection{Thresholding}
Thresholding is a very simple and common approach to segmentation.
This method is applied on the \textit{histogram} of the image.
The histogram of a digital image with intensity levels $L$ in the range $[0, \: L-1]$, is a discrete function $h(l_k) = n_k$ where $l_k$ is the k-th intensity value and $n_k$  is the number of pixels with intensity $l_k$.\\
Thresholding consists in binarizing an image through an (if) clause on the intensity value of each pixel.
This is done setting a threshold value $T \in [0, \: L-1]$.
The threshold value $T$ is usually chosen by visual assessment on the image histogram but it can be automatize by algorithms like the \textit{Otsu algorithm}.\\
One drawback of this method is that some parts of the image can belong to the same class even if they belong to different objects.
In fact, thresholding does not take into account the spatial characteristics of the image.
Moreover, it is sensitive to noise and intensity inhomogeneity that can corrupt the image histogram and make difficult the classification of pixels\cite{biondi}.

\subsubsection{Convolutional Neural Networks} 
Convolutional Neural Networks (CNNs) are computational architectures commonly applied to analyze visual imagery.
They belong to the class of Deep Neural Network, using a variation of the multilayer perceptrons.
The word \textit{Convolutional} indicates that the network employs convolution operations.
A typical Convolutional Neural Network architectures is made up of three main structures: an \textit{input layer} that is the set of data, \textit{hidden layers} and an \textit{output layer}.
\\
The hidden layers include different units.
Among them we find convolutional layers, that consist of convolution kernel sliding along the input matrix.
The convolution operation generates a feature map, which in turn contributes to the input of the next layer\cite{CNN}.
This process can be followed by other kinds of layers such as \textit{Activation layers}, \textit{Pooling layers}, \textit{Up-convolution layers}, each one with a different purpose.
For example, the Pooling layer aims to reduce the dimensions of the feature maps; the Activation layer, consists of a pixel-wise non-linear function, usually the Rectified Linear Unit (ReLU); the Up-convolution layers aims to up-sample the feature maps.
The choice of the layers depends on the characteristics of the problem and the kind of network architecture considered.
\\
The last layer, the \textit{output layer}, provides the result of the classification of the network resulting in a vector containing the belonging probability score of the object to the classes.
For this purpose, different functions can be used \cite{camborata}.
In particular, for binary segmentation tasks, one of the most used is the Sigmoid function:
\begin{equation}
    Sigmoid(x) = \frac{1}{1 + e^{-x}}
\end{equation}
Other components of the network structure are the optimizers and the loss function. 
Optimizer are methods responsible of changing the attributes of the neural network such as weights and learning rate to reduce the losses. 
The most used is the Adaptive moment estimation (Adam)\cite{jovana}. 
\\
The loss function affects the training phase by evaluating the error rate.
This function must be minimized. 
Popular loss functions for segmentation purposes include the binary cross-entropy (BCE) and the Categorical Cross-Entropy (CCE):

\begin{align}
    BCE(q) &= - \frac{1}{N} \sum_{i = 1}^{N} y_i \cdot log(p(y_i)) + (1 - y_i) \cdot log(1 - p(y_i)) \\ 
    CCE(q) &=  \sum_{i = 1}^{K} q(y_i) \cdot log(p(y_i))
\end{align}
where for N data points and K classes, $y_i$ is the truth-label and $p(y_i)$ is the probability for the $i^{th}$ class.
\\
However, we can choose between a wide range of different loss functions\cite{camborata}.
In particular, for this project the loss function consists of the combination between the Dice loss with the binary focal loss\cite{focal}.
The former comes from the Dice similarity coefficient (DSC):
\begin{equation}
    DL(y, \hat{p}) = 1 - \frac{2y\hat{p} + 1}{y + \hat{p} + 1}
\end{equation}
where $y$ is the the truth-label and $\hat{p}$ is the the predicted probability.
Here, 1 is added in numerator and denominator to ensure that the function is not undefined in edge case scenarios such as when $y = \hat{p} = 0$.
\\
The latter instead can be defined: 
\begin{equation}
    FL(y, \hat{p}) = - \alpha y(1 - \hat{p})^{\gamma}log(\hat{p}) - \alpha (1 - y) \hat{p}^{\gamma}log(1 - \hat{p})
\end{equation}
where $y$ is the the truth-label, $\hat{p}$ is the predicted probability, $\alpha$ is weighting factor and $\gamma$ a focusing parameter.
\\
The performance of the network is measured by a function called metric.
Metric functions are similar to loss function but they do not have to be minimized.
\\
Several architectures have been developed over the years, for different tasks and fields of application.
In bio-medical image processing, the so-called U-Net, is one of the most common and used architecture\cite{unet}.



\end{document}